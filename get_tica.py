from deeptime.decomposition import TICA
from deeptime.util.data import TimeLaggedDataset
from deeptime.clustering import KMeans
import mdtraj as mdj
import numpy as np
import pickle as pkl
import sys
import time
import sys

def get_init_final_frame_index(feat_dict):

    """For a feature dictionary generated by the calc_feature codes of this repo,
    this function provides the first and the last index of frame in each system.

    Parameters
    ----------

    feature_dict: dictionary
        A dictionary of features, where each key corresponds to each of the 
        different systems that are stored inside the feature_dict.
        Each feature_dict[system] is also a dictionary by construction if you
        follow our data storage process. The keys of feature_dict[system] are 
        the runs of the systems. Each feature_dict[system][run] has a numpy array
        or a list of features.
        Please use the feature extractor code of this package to generate the 
        features before proceeding with tica computation.


    Returns
    -------

    system_index : dictionary
        A dict with keys of system identifier as it is from the feature dictionary.
        Each value corresponding to a key is a list of two items.
        The first item is the starting index of the feature of that system.
        The second (last) item is the index corresponding to the last feature of that system.
        Remember, it considers all the runs. 
    """

    
    system_index = {}
    count = 0

    # init the dict as list
    for keys in feat_dict.keys():
        system_index[keys] = []

    # load the list with initial and final frame index
    for keys in feat_dict.keys():
        system_index[keys].append(count)
        for runs in feat_dict[keys].keys():
            count += len(feat_dict[keys][runs])
        system_index[keys].append(count)
    
    return(system_index)


def build_co_tica_tld(co_tica_system_dict, inp_folder_path, input_str, tau):

    """This function builds a combined, time-lagged dataset to train tica.
    This is essential prior to tica as one would need the time lagged data
    to train the model. 
    Please note that this function effectively helps building co-TICA datasets
    where two or more different systems are being compared. Hence, the co_tica_system_dict
    input inherently can work with multiple systems. However, if you are working 
    with one system only, please use the same function but ensure that your 
    co_tica_system_dict have only one key i.e., that system only.

    Parameters
    ----------

    co_tica_system_dict: dictionary

        The system dictionary has to follow some certain rules.
        The keys of the dictionary must denote all the different type of systems
        (or conditions) that have been simulated for comparison and that you want to combine.
        The first value should be the string containing the path where one would get all topology/dcds.
        The second value should be the number of independent runs (replicates).
        The third value should be a list that contains how many substeps are there
        in each individual run of the systems.
 


    Returns
    -------

    t0_data: list
        Features for building the time lagged dataset to train the tica model
        subsequently.
        This is a list of features at the initial timepoint (t = t0).
    
    t1_data: list
        Features at time-lagged point (t = t0 + tau)

    n_features: arraylike
        Number of features 
    
    """


    t0_data = []
    t1_data = []

    for keys in co_tica_system_dict.keys():

        filename = f'{inp_folder_path}/{keys}_{input_str}.pkl'
        feat_dict = pkl.load(open(filename, 'rb'))
        
        for runs in feat_dict.keys():

            run_feat_arr = feat_dict[runs]
            data_length = run_feat_arr.shape[0] - tau
            
            #print(f'System{keys}, run{runs}, data length: {data_length}')
            n_features = run_feat_arr.shape[1]

            for i in range(data_length):
                t0_data.append(run_feat_arr[i])
                t1_data.append(run_feat_arr[i+tau])

    return t0_data, t1_data, n_features

def predict_tica_vectors(model, co_tica_system_dict, inp_folder_path, input_str , num_features, num_reshape):

    tica_feats = {}

    for keys in co_tica_system_dict.keys():
        tica_feats[keys] = {}

        filename = f'{inp_folder_path}/{keys}_{input_str}.pkl'
        feat_dict = pkl.load(open(filename, 'rb'))

        for runs in feat_dict.keys():
            print(f'System:{keys}, run{runs}...')
            run_feat_arr = feat_dict[runs].reshape(feat_dict[runs].shape[0], num_features*num_reshape)
            tica_feats[keys][runs] = [model.transform(item) for item in run_feat_arr]

    return tica_feats

if __name__ == '__main__':

    tau_list = [1,5,10,50,75,100,120,150,200]
    n_tica_dim_list = [2,5]

    base_path = '/dickson/s1/bosesami/REVO_tica_attempts/clr_swing_in_out/distance_based'
    inp_path = f'{base_path}/distance_features/'
    tica_path = f'{base_path}/tica/'

    MD_data_path = f'/dickson/s1/bosesami/clr_ramp_work/standard_MD/'

    output_str = 'clrBackboneCB_rampCA_distancefeat_allsystems'
    input_str = 'clrBackboneCB_rampCA_distances_70dim'

    sys_dict = {
               'R1': [f'{MD_data_path}/R1/', 5, 2034, [2000,2000,2000,2000,2000], 'charmm-gui-5614072231/openmm', [1063,1064,1065,1066,1067]],
               'R3': [f'{MD_data_path}/R3/', 5, 88, [2000,2000,2000,2000,2000], 'charmm-gui-5614871995/openmm', [37,38,39,40,41]]
               }


    if int(sys.argv[1]) not in (1,3):
        print('Feature type argument must be provided:')
        print('For distance features use argument 1')
        print('For coordinate features use argument 3')
    else:
        n_reshape = int(sys.argv[1])
        

    for tau in tau_list:
        for n_tica_dim in n_tica_dim_list:

            print(f'Running for lag, n_tic: {tau}, {n_tica_dim}')

            ### Building the FULL time lagged dataset
            t0_data, t1_data, n_features = build_co_tica_tld(co_tica_system_dict = sys_dict, 
                                                             inp_folder_path = inp_path, 
                                                             input_str = input_str, 
                                                             tau = tau)

            reshaped_t0 = np.reshape(t0_data, (len(t0_data),n_features*n_reshape))
            reshaped_t1 = np.reshape(t1_data, (len(t1_data),n_features*n_reshape))
            
            big_tld = TimeLaggedDataset(reshaped_t0, reshaped_t1)

            ### Building the tica estimator object
            t1= time.time()
            print("Start: Training TICA..")
            estimator = TICA(dim=n_tica_dim, lagtime=tau).fit(big_tld).fetch_model()
            
            ## Store the tica model
            pkl.dump(estimator, open(f'{tica_path}/ticaModel_{output_str}_{n_tica_dim}nTIC_{tau}lag.pkl','wb'))
            
            ### Finally get the components: system and runs as dictionary keys.
            tica_feats = predict_tica_vectors(model = estimator, 
                                             co_tica_system_dict = sys_dict, 
                                             inp_folder_path = inp_path, 
                                             input_str = input_str,
                                             num_features = n_features,
                                             num_reshape = n_reshape)
            
            t2 = time.time()

            print(f"TICA featurization with n_TIC {n_tica_dim}, time taken: {t2 -t1} seconds...")
            pkl.dump(tica_feats, open(f'{tica_path}/coTICA_{output_str}_{n_tica_dim}nTIC_{tau}lag.pkl','wb'))
            
